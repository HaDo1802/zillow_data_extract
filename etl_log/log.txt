2026-01-25 06:48:53 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:48:53 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:49:24 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:49:24 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:49:28 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:49:28 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:49:58 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:49:58 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:50:29 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:50:29 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:50:59 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:50:59 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:51:30 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:51:30 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:51:46 | INFO     | airflow.task | Starting extract_zillow. Will write to: /opt/airflow/data/raw/raw_latest.csv
2026-01-25 06:51:46 | INFO     | etl.extract | STARTING DATA EXTRACTION FROM ALL LISTED LOCATIONS
2026-01-25 06:51:46 | INFO     | etl.extract | Locations configured: 1
2026-01-25 06:51:46 | INFO     | etl.extract | Target locations: Las Vegas, NV
2026-01-25 06:51:46 | INFO     | etl.extract | Processing location: Las Vegas, NV
2026-01-25 06:51:46 | INFO     | etl.extract | Starting extraction for location: Las Vegas, NV (max_pages: 2)
2026-01-25 06:51:46 | INFO     | etl.extract | Fetching page 1 for Las Vegas, NV
2026-01-25 06:51:49 | INFO     | etl.extract | Page 1 fetched successfully - Properties: 41, Duration: 2.33s
2026-01-25 06:51:49 | INFO     | etl.extract | Fetching page 2 for Las Vegas, NV
2026-01-25 06:51:51 | INFO     | etl.extract | Page 2 fetched successfully - Properties: 41, Duration: 1.94s
2026-01-25 06:51:51 | INFO     | etl.extract | Extraction complete for Las Vegas, NV - Total properties: 82, Pages processed: 2
2026-01-25 06:51:51 | INFO     | etl.extract | SUCCESS - Fetched 82 properties from Las Vegas, NV
2026-01-25 06:51:53 | INFO     | etl.extract | EXTRACTION SUMMARY
2026-01-25 06:51:53 | INFO     | etl.extract | Locations processed: 1
2026-01-25 06:51:53 | INFO     | etl.extract | Successful: 1
2026-01-25 06:51:53 | INFO     | etl.extract | Failed: 0
2026-01-25 06:51:53 | INFO     | etl.extract | Total properties fetched: 82
2026-01-25 06:51:53 | INFO     | etl.extract | Unique properties: 81
2026-01-25 06:51:53 | INFO     | etl.extract | Duplicates removed: 1
2026-01-25 06:51:53 | INFO     | etl.extract | Saved timestamped file: /opt/airflow/data/raw/raw_20260125.csv
2026-01-25 06:51:53 | INFO     | etl.extract | Saved latest file: /opt/airflow/data/raw/raw_latest.csv
2026-01-25 06:51:53 | INFO     | airflow.task | Fetched dataframe shape=(81, 33)
2026-01-25 06:51:53 | INFO     | airflow.task | Wrote raw CSV successfully: /opt/airflow/data/raw/raw_latest.csv (rows=81)
2026-01-25 06:51:53 | INFO     | airflow.task.operators.airflow.decorators.python._PythonDecoratedOperator | Done. Returned value was: {'records_extracted': 81, 'unique_properties': 81, 'file_path': '/opt/airflow/data/raw/raw_latest.csv', 'extraction_timestamp': '2026-01-25T06:51:53.573806'}
2026-01-25 06:51:53 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 06:51:53 | INFO     | airflow.models.taskinstance | Marking task as SUCCESS. dag_id=real_estate_etl_taskflow, task_id=extract_zillow, run_id=scheduled__2026-01-24T06:00:00+00:00, execution_date=20260124T060000, start_date=20260125T065146, end_date=20260125T065153
2026-01-25 06:51:58 | INFO     | etl.transform | STARTING DATA TRANSFORMATION
2026-01-25 06:51:58 | INFO     | etl.transform | Reading input file: /opt/airflow/data/raw/raw_latest.csv
2026-01-25 06:51:58 | INFO     | etl.transform | Loaded 81 raw records
2026-01-25 06:51:58 | INFO     | etl.transform | Columns found: 33
2026-01-25 06:51:58 | INFO     | etl.transform | Step 1: Extracting address components...
2026-01-25 06:51:58 | INFO     | etl.transform | Address components extracted successfully
2026-01-25 06:51:58 | INFO     | etl.transform | Step 2: Extracting listing subtype information...
2026-01-25 06:51:58 | INFO     | etl.transform | Listing subtype flags extracted
2026-01-25 06:51:58 | INFO     | etl.transform | Step 3: Converting timestamp fields...
2026-01-25 06:51:58 | INFO     | etl.transform | Converted datePriceChanged to datetime
2026-01-25 06:51:58 | INFO     | etl.transform | Step 4: Add snapshot dates...
2026-01-25 06:51:58 | INFO     | etl.transform | Snapshot dates added
2026-01-25 06:51:58 | INFO     | etl.transform | Step 5: Normalizing lot area to square feet...
2026-01-25 06:51:58 | INFO     | etl.transform | Lot areas normalized to sqft
2026-01-25 06:51:58 | INFO     | etl.transform | Step 6: Extracting Vegas districts...
2026-01-25 06:51:58 | INFO     | etl.transform | Identified 6 unique districts
2026-01-25 06:51:58 | INFO     | etl.transform | Step 7: Removing unnecessary columns...
2026-01-25 06:51:58 | INFO     | etl.transform | Removed 7 unnecessary columns
2026-01-25 06:51:58 | INFO     | etl.transform | Processed at: 2026-01-25 06:51:58
2026-01-25 06:51:58 | INFO     | etl.transform | All records passed essential field validation
2026-01-25 06:51:58 | INFO     | etl.transform | Final record count: 81
2026-01-25 06:51:58 | INFO     | etl.transform | Saved timestamped file: /opt/airflow/data/transformed/transformed_20260125.csv
2026-01-25 06:51:58 | INFO     | etl.transform | Saved latest file: /opt/airflow/data/transformed/transformed_latest.csv
2026-01-25 06:51:58 | INFO     | etl.transform | TRANSFORMATION SUMMARY
2026-01-25 06:51:58 | INFO     | etl.transform | Input file: raw_latest.csv
2026-01-25 06:51:58 | INFO     | etl.transform | Initial records: 81
2026-01-25 06:51:58 | INFO     | etl.transform | Final records: 81
2026-01-25 06:51:58 | INFO     | etl.transform | Records filtered: 0 (0.0%)
2026-01-25 06:51:58 | INFO     | etl.transform | Output directory: /opt/airflow/data/transformed
2026-01-25 06:51:58 | INFO     | airflow.task.operators.airflow.decorators.python._PythonDecoratedOperator | Done. Returned value was: {'records_transformed': 81, 'file_path': '/opt/airflow/data/transformed/transformed_latest.csv', 'transformation_efficiency': 100.0, 'records_filtered': 0}
2026-01-25 06:51:58 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 06:51:58 | INFO     | airflow.models.taskinstance | Marking task as SUCCESS. dag_id=real_estate_etl_taskflow, task_id=transform_data, run_id=scheduled__2026-01-24T06:00:00+00:00, execution_date=20260124T060000, start_date=20260125T065157, end_date=20260125T065158
2026-01-25 06:52:00 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:52:00 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:52:00 | INFO     | etl.load | STARTING DATA LOAD TO POSTGRESQL
2026-01-25 06:52:00 | INFO     | etl.load | Loading file: /opt/airflow/data/transformed/transformed_latest.csv
2026-01-25 06:52:00 | INFO     | etl.load | Connecting to PostgreSQL (docker): postgres:5432/docker_real_estate as db_user
2026-01-25 06:52:00 | INFO     | etl.load | Creating schema if not exists: real_estate_data
2026-01-25 06:52:00 | INFO     | etl.load | Creating table if not exists: real_estate_data.properties_data_history
2026-01-25 06:52:00 | INFO     | etl.load | Schema and objects verified/created
2026-01-25 06:52:00 | INFO     | etl.load | Loaded 81 records from CSV
2026-01-25 06:52:00 | INFO     | etl.load | Columns: 27
2026-01-25 06:52:00 | INFO     | etl.load | Created temporary file: /tmp/property_history_load.csv
2026-01-25 06:52:00 | INFO     | etl.load | COPY completed successfully
2026-01-25 06:52:00 | INFO     | etl.load | Total rows in history table: 573
2026-01-25 06:52:00 | INFO     | etl.load | Database connection closed
2026-01-25 06:52:00 | INFO     | airflow.task.operators.airflow.decorators.python._PythonDecoratedOperator | Done. Returned value was: {'postgres_rows': 573, 'records_loaded': 81}
2026-01-25 06:52:00 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 06:52:00 | INFO     | airflow.models.taskinstance | Marking task as SUCCESS. dag_id=real_estate_etl_taskflow, task_id=load_postgres, run_id=scheduled__2026-01-24T06:00:00+00:00, execution_date=20260124T060000, start_date=20260125T065200, end_date=20260125T065200
2026-01-25 06:52:02 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 06:52:02 | ERROR    | airflow.task | Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/test_dag.py", line 197, in load_s3
    file_path = transform_metrics["file_path"]
KeyError: 'file_path'
2026-01-25 06:52:02 | INFO     | airflow.models.taskinstance | Marking task as UP_FOR_RETRY. dag_id=real_estate_etl_taskflow, task_id=load_s3, run_id=scheduled__2026-01-24T06:00:00+00:00, execution_date=20260124T060000, start_date=20260125T065202, end_date=20260125T065202
2026-01-25 06:52:02 | ERROR    | airflow.task.task_runner.standard_task_runner.StandardTaskRunner | Failed to execute job 74 for task load_s3 ('file_path'; 6591)
2026-01-25 06:52:31 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:52:31 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:53:01 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:53:01 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:53:32 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:53:32 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:54:02 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:54:02 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:54:34 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:54:34 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:54:47 | INFO     | airflow.task | Starting extract_zillow. Will write to: /opt/airflow/data/raw/raw_latest.csv
2026-01-25 06:54:47 | INFO     | etl.extract | STARTING DATA EXTRACTION FROM ALL LISTED LOCATIONS
2026-01-25 06:54:47 | INFO     | etl.extract | Locations configured: 1
2026-01-25 06:54:47 | INFO     | etl.extract | Target locations: Las Vegas, NV
2026-01-25 06:54:47 | INFO     | etl.extract | Processing location: Las Vegas, NV
2026-01-25 06:54:47 | INFO     | etl.extract | Starting extraction for location: Las Vegas, NV (max_pages: 2)
2026-01-25 06:54:47 | INFO     | etl.extract | Fetching page 1 for Las Vegas, NV
2026-01-25 06:54:48 | INFO     | etl.extract | Page 1 fetched successfully - Properties: 41, Duration: 0.5s
2026-01-25 06:54:48 | INFO     | etl.extract | Fetching page 2 for Las Vegas, NV
2026-01-25 06:54:49 | INFO     | etl.extract | Page 2 fetched successfully - Properties: 41, Duration: 0.45s
2026-01-25 06:54:49 | INFO     | etl.extract | Extraction complete for Las Vegas, NV - Total properties: 82, Pages processed: 2
2026-01-25 06:54:49 | INFO     | etl.extract | SUCCESS - Fetched 82 properties from Las Vegas, NV
2026-01-25 06:54:51 | INFO     | etl.extract | EXTRACTION SUMMARY
2026-01-25 06:54:51 | INFO     | etl.extract | Locations processed: 1
2026-01-25 06:54:51 | INFO     | etl.extract | Successful: 1
2026-01-25 06:54:51 | INFO     | etl.extract | Failed: 0
2026-01-25 06:54:51 | INFO     | etl.extract | Total properties fetched: 82
2026-01-25 06:54:51 | INFO     | etl.extract | Unique properties: 81
2026-01-25 06:54:51 | INFO     | etl.extract | Duplicates removed: 1
2026-01-25 06:54:51 | INFO     | etl.extract | Saved timestamped file: /opt/airflow/data/raw/raw_20260125.csv
2026-01-25 06:54:51 | INFO     | etl.extract | Saved latest file: /opt/airflow/data/raw/raw_latest.csv
2026-01-25 06:54:51 | INFO     | airflow.task | Fetched dataframe shape=(81, 33)
2026-01-25 06:54:51 | INFO     | airflow.task | Wrote raw CSV successfully: /opt/airflow/data/raw/raw_latest.csv (rows=81)
2026-01-25 06:54:51 | INFO     | airflow.task.operators.airflow.decorators.python._PythonDecoratedOperator | Done. Returned value was: {'records_extracted': 81, 'unique_properties': 81, 'file_path': '/opt/airflow/data/raw/raw_latest.csv', 'extraction_timestamp': '2026-01-25T06:54:51.376942'}
2026-01-25 06:54:51 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 06:54:51 | INFO     | airflow.models.taskinstance | Marking task as SUCCESS. dag_id=real_estate_etl_taskflow, task_id=extract_zillow, run_id=manual__2026-01-25T06:49:39.854159+00:00, execution_date=20260125T064939, start_date=20260125T065447, end_date=20260125T065451
2026-01-25 06:54:53 | INFO     | etl.transform | STARTING DATA TRANSFORMATION
2026-01-25 06:54:53 | INFO     | etl.transform | Reading input file: /opt/airflow/data/raw/raw_latest.csv
2026-01-25 06:54:53 | INFO     | etl.transform | Loaded 81 raw records
2026-01-25 06:54:53 | INFO     | etl.transform | Columns found: 33
2026-01-25 06:54:53 | INFO     | etl.transform | Step 1: Extracting address components...
2026-01-25 06:54:53 | INFO     | etl.transform | Address components extracted successfully
2026-01-25 06:54:53 | INFO     | etl.transform | Step 2: Extracting listing subtype information...
2026-01-25 06:54:53 | INFO     | etl.transform | Listing subtype flags extracted
2026-01-25 06:54:53 | INFO     | etl.transform | Step 3: Converting timestamp fields...
2026-01-25 06:54:53 | INFO     | etl.transform | Converted datePriceChanged to datetime
2026-01-25 06:54:53 | INFO     | etl.transform | Step 4: Add snapshot dates...
2026-01-25 06:54:53 | INFO     | etl.transform | Snapshot dates added
2026-01-25 06:54:53 | INFO     | etl.transform | Step 5: Normalizing lot area to square feet...
2026-01-25 06:54:53 | INFO     | etl.transform | Lot areas normalized to sqft
2026-01-25 06:54:53 | INFO     | etl.transform | Step 6: Extracting Vegas districts...
2026-01-25 06:54:53 | INFO     | etl.transform | Identified 6 unique districts
2026-01-25 06:54:53 | INFO     | etl.transform | Step 7: Removing unnecessary columns...
2026-01-25 06:54:53 | INFO     | etl.transform | Removed 7 unnecessary columns
2026-01-25 06:54:53 | INFO     | etl.transform | Processed at: 2026-01-25 06:54:53
2026-01-25 06:54:53 | INFO     | etl.transform | All records passed essential field validation
2026-01-25 06:54:53 | INFO     | etl.transform | Final record count: 81
2026-01-25 06:54:53 | INFO     | etl.transform | Saved timestamped file: /opt/airflow/data/transformed/transformed_20260125.csv
2026-01-25 06:54:53 | INFO     | etl.transform | Saved latest file: /opt/airflow/data/transformed/transformed_latest.csv
2026-01-25 06:54:53 | INFO     | etl.transform | TRANSFORMATION SUMMARY
2026-01-25 06:54:53 | INFO     | etl.transform | Input file: raw_latest.csv
2026-01-25 06:54:53 | INFO     | etl.transform | Initial records: 81
2026-01-25 06:54:53 | INFO     | etl.transform | Final records: 81
2026-01-25 06:54:53 | INFO     | etl.transform | Records filtered: 0 (0.0%)
2026-01-25 06:54:53 | INFO     | etl.transform | Output directory: /opt/airflow/data/transformed
2026-01-25 06:54:53 | INFO     | airflow.task.operators.airflow.decorators.python._PythonDecoratedOperator | Done. Returned value was: {'records_transformed': 81, 'file_path': '/opt/airflow/data/transformed/transformed_latest.csv', 'transformation_efficiency': 100.0, 'records_filtered': 0}
2026-01-25 06:54:53 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 06:54:53 | INFO     | airflow.models.taskinstance | Marking task as SUCCESS. dag_id=real_estate_etl_taskflow, task_id=transform_data, run_id=manual__2026-01-25T06:49:39.854159+00:00, execution_date=20260125T064939, start_date=20260125T065453, end_date=20260125T065453
2026-01-25 06:54:55 | INFO     | etl.load | STARTING DATA LOAD TO POSTGRESQL
2026-01-25 06:54:55 | INFO     | etl.load | Loading file: /opt/airflow/data/transformed/transformed_latest.csv
2026-01-25 06:54:55 | INFO     | etl.load | Connecting to PostgreSQL (docker): postgres:5432/docker_real_estate as db_user
2026-01-25 06:54:55 | INFO     | etl.load | Creating schema if not exists: real_estate_data
2026-01-25 06:54:55 | INFO     | etl.load | Creating table if not exists: real_estate_data.properties_data_history
2026-01-25 06:54:55 | INFO     | etl.load | Schema and objects verified/created
2026-01-25 06:54:55 | INFO     | etl.load | Loaded 81 records from CSV
2026-01-25 06:54:55 | INFO     | etl.load | Columns: 27
2026-01-25 06:54:55 | INFO     | etl.load | Created temporary file: /tmp/property_history_load.csv
2026-01-25 06:54:55 | INFO     | etl.load | COPY completed successfully
2026-01-25 06:54:55 | INFO     | etl.load | Total rows in history table: 654
2026-01-25 06:54:55 | INFO     | etl.load | Database connection closed
2026-01-25 06:54:55 | INFO     | airflow.task.operators.airflow.decorators.python._PythonDecoratedOperator | Done. Returned value was: {'postgres_rows': 654, 'records_loaded': 81}
2026-01-25 06:54:55 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 06:54:55 | INFO     | airflow.models.taskinstance | Marking task as SUCCESS. dag_id=real_estate_etl_taskflow, task_id=load_postgres, run_id=manual__2026-01-25T06:49:39.854159+00:00, execution_date=20260125T064939, start_date=20260125T065455, end_date=20260125T065455
2026-01-25 06:54:56 | INFO     | botocore.credentials | Found credentials in environment variables.
2026-01-25 06:54:57 | INFO     | etl.load_to_s3 | File /opt/airflow/data/transformed/transformed_latest.csv uploaded to s3://real-estate-scraped-data/transformed/transformed_latest.csv
2026-01-25 06:54:57 | INFO     | airflow.task.operators.airflow.decorators.python._PythonDecoratedOperator | Done. Returned value was: {'s3_success': True, 'bucket': 'real-estate-scraped-data'}
2026-01-25 06:54:57 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 06:54:57 | INFO     | airflow.models.taskinstance | Marking task as SUCCESS. dag_id=real_estate_etl_taskflow, task_id=load_s3, run_id=manual__2026-01-25T06:49:39.854159+00:00, execution_date=20260125T064939, start_date=20260125T065456, end_date=20260125T065457
2026-01-25 06:54:58 | INFO     | etl.email_notifier | Email notifier initialized: havando1802@gmail.com -> havando1802@gmail.com
2026-01-25 06:54:58 | INFO     | etl.email_notifier | Preparing success email notification...
2026-01-25 06:54:58 | INFO     | etl.email_notifier | Connecting to SMTP server: smtp.gmail.com:587
2026-01-25 06:55:00 | INFO     | etl.email_notifier | Email notification sent successfully to havando1802@gmail.com
2026-01-25 06:55:00 | INFO     | airflow.task.operators.airflow.decorators.python._PythonDecoratedOperator | Done. Returned value was: None
2026-01-25 06:55:00 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 06:55:00 | INFO     | airflow.models.taskinstance | Marking task as SUCCESS. dag_id=real_estate_etl_taskflow, task_id=send_notification, run_id=manual__2026-01-25T06:49:39.854159+00:00, execution_date=20260125T064939, start_date=20260125T065458, end_date=20260125T065500
2026-01-25 06:55:04 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:55:04 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:55:35 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:55:35 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:56:06 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:56:06 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:56:36 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:56:36 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:57:06 | INFO     | botocore.credentials | Found credentials in environment variables.
2026-01-25 06:57:06 | INFO     | etl.load_to_s3 | File /opt/airflow/data/raw/raw_latest.csv uploaded to s3://real-estate-scraped-data/raw/raw_latest.csv
2026-01-25 06:57:07 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:57:07 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:57:07 | INFO     | etl.load_to_s3 | File /opt/airflow/data/transformed/transformed_latest.csv uploaded to s3://real-estate-scraped-data/transformed/transformed_latest.csv
2026-01-25 06:57:07 | INFO     | airflow.task.operators.airflow.decorators.python._PythonDecoratedOperator | Done. Returned value was: {'s3_success': True, 'bucket': 'real-estate-scraped-data'}
2026-01-25 06:57:07 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 06:57:07 | INFO     | airflow.models.taskinstance | Marking task as SUCCESS. dag_id=real_estate_etl_taskflow, task_id=load_s3, run_id=scheduled__2026-01-24T06:00:00+00:00, execution_date=20260124T060000, start_date=20260125T065705, end_date=20260125T065707
2026-01-25 06:57:09 | INFO     | etl.email_notifier | Email notifier initialized: havando1802@gmail.com -> havando1802@gmail.com
2026-01-25 06:57:09 | INFO     | etl.email_notifier | Preparing success email notification...
2026-01-25 06:57:09 | INFO     | etl.email_notifier | Connecting to SMTP server: smtp.gmail.com:587
2026-01-25 06:57:10 | INFO     | etl.email_notifier | Email notification sent successfully to havando1802@gmail.com
2026-01-25 06:57:10 | INFO     | airflow.task.operators.airflow.decorators.python._PythonDecoratedOperator | Done. Returned value was: None
2026-01-25 06:57:10 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 06:57:10 | INFO     | airflow.models.taskinstance | Marking task as SUCCESS. dag_id=real_estate_etl_taskflow, task_id=send_notification, run_id=scheduled__2026-01-24T06:00:00+00:00, execution_date=20260124T060000, start_date=20260125T065708, end_date=20260125T065710
2026-01-25 06:57:21 | INFO     | botocore.credentials | Found credentials in environment variables.
2026-01-25 06:57:21 | INFO     | etl.load_to_s3 | File /opt/airflow/data/raw/raw_latest.csv uploaded to s3://real-estate-scraped-data/raw/raw_latest.csv
2026-01-25 06:57:22 | INFO     | etl.load_to_s3 | File /opt/airflow/data/transformed/transformed_latest.csv uploaded to s3://real-estate-scraped-data/transformed/transformed_latest.csv
2026-01-25 06:57:22 | INFO     | airflow.task.operators.airflow.decorators.python._PythonDecoratedOperator | Done. Returned value was: {'s3_success': True, 'bucket': 'real-estate-scraped-data'}
2026-01-25 06:57:22 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 06:57:22 | INFO     | airflow.models.taskinstance | Marking task as SUCCESS. dag_id=real_estate_etl_taskflow, task_id=load_s3, run_id=scheduled__2026-01-24T06:00:00+00:00, execution_date=20260124T060000, start_date=20260125T065720, end_date=20260125T065722
2026-01-25 06:57:24 | INFO     | etl.email_notifier | Email notifier initialized: havando1802@gmail.com -> havando1802@gmail.com
2026-01-25 06:57:24 | INFO     | etl.email_notifier | Preparing success email notification...
2026-01-25 06:57:24 | INFO     | etl.email_notifier | Connecting to SMTP server: smtp.gmail.com:587
2026-01-25 06:57:25 | INFO     | etl.email_notifier | Email notification sent successfully to havando1802@gmail.com
2026-01-25 06:57:25 | INFO     | airflow.task.operators.airflow.decorators.python._PythonDecoratedOperator | Done. Returned value was: None
2026-01-25 06:57:25 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 06:57:25 | INFO     | airflow.models.taskinstance | Marking task as SUCCESS. dag_id=real_estate_etl_taskflow, task_id=send_notification, run_id=scheduled__2026-01-24T06:00:00+00:00, execution_date=20260124T060000, start_date=20260125T065723, end_date=20260125T065725
2026-01-25 06:57:38 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:57:38 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:58:08 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:58:08 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:58:39 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:58:39 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:59:10 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:59:10 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 06:59:40 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 06:59:40 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:00:11 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:00:11 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:00:42 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:00:42 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:01:13 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:01:13 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:01:43 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:01:44 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:02:14 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:02:14 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:02:45 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:02:45 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:03:15 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:03:15 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:03:46 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:03:46 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:04:17 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:04:17 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:05:22 | ERROR    | airflow.models.dagbag.DagBag | Failed to import: /opt/airflow/dags/test_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/test_dag.py", line 274, in <module>
    real_estate_dag = real_estate_etl_pipeline()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dag.py", line 4081, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_dag.py", line 255, in real_estate_etl_pipeline
    s3 = load_s3(transformation)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/decorators/base.py", line 372, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/decorators/python.py", line 52, in __init__
    super().__init__(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/decorators/base.py", line 253, in __init__
    signature.bind(*op_args, **op_kwargs)
  File "/usr/local/lib/python3.9/inspect.py", line 3045, in bind
    return self._bind(args, kwargs)
  File "/usr/local/lib/python3.9/inspect.py", line 2960, in _bind
    raise TypeError(msg) from None
TypeError: missing a required argument: 'extraction_metrics'
2026-01-25 07:05:28 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:05:28 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:05:59 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:05:59 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:06:30 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:06:30 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:07:01 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:07:01 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:07:30 | INFO     | airflow.task | Starting extract_zillow. Will write to: /opt/airflow/data/raw/raw_latest.csv
2026-01-25 07:07:30 | INFO     | etl.extract | STARTING DATA EXTRACTION FROM ALL LISTED LOCATIONS
2026-01-25 07:07:30 | INFO     | etl.extract | Locations configured: 1
2026-01-25 07:07:30 | INFO     | etl.extract | Target locations: Las Vegas, NV
2026-01-25 07:07:30 | INFO     | etl.extract | Processing location: Las Vegas, NV
2026-01-25 07:07:30 | INFO     | etl.extract | Starting extraction for location: Las Vegas, NV (max_pages: 2)
2026-01-25 07:07:30 | INFO     | etl.extract | Fetching page 1 for Las Vegas, NV
2026-01-25 07:07:31 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:07:31 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:07:31 | INFO     | etl.extract | Page 1 fetched successfully - Properties: 41, Duration: 1.24s
2026-01-25 07:07:32 | INFO     | etl.extract | Fetching page 2 for Las Vegas, NV
2026-01-25 07:07:33 | INFO     | etl.extract | Page 2 fetched successfully - Properties: 41, Duration: 0.92s
2026-01-25 07:07:33 | INFO     | etl.extract | Extraction complete for Las Vegas, NV - Total properties: 82, Pages processed: 2
2026-01-25 07:07:33 | INFO     | etl.extract | SUCCESS - Fetched 82 properties from Las Vegas, NV
2026-01-25 07:07:35 | INFO     | etl.extract | EXTRACTION SUMMARY
2026-01-25 07:07:35 | INFO     | etl.extract | Locations processed: 1
2026-01-25 07:07:35 | INFO     | etl.extract | Successful: 1
2026-01-25 07:07:35 | INFO     | etl.extract | Failed: 0
2026-01-25 07:07:35 | INFO     | etl.extract | Total properties fetched: 82
2026-01-25 07:07:35 | INFO     | etl.extract | Unique properties: 82
2026-01-25 07:07:35 | INFO     | etl.extract | Duplicates removed: 0
2026-01-25 07:07:35 | INFO     | etl.extract | Saved timestamped file: /opt/airflow/data/raw/raw_20260125.csv
2026-01-25 07:07:35 | INFO     | etl.extract | Saved latest file: /opt/airflow/data/raw/raw_latest.csv
2026-01-25 07:07:35 | INFO     | airflow.task | Fetched dataframe shape=(82, 33)
2026-01-25 07:07:35 | INFO     | airflow.task | Wrote raw CSV successfully: /opt/airflow/data/raw/raw_latest.csv (rows=82)
2026-01-25 07:07:35 | INFO     | airflow.task.operators.airflow.decorators.python._PythonDecoratedOperator | Done. Returned value was: {'records_extracted': 82, 'unique_properties': 82, 'file_path': '/opt/airflow/data/raw/raw_latest.csv', 'extraction_timestamp': '2026-01-25T07:07:35.493096'}
2026-01-25 07:07:35 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 07:07:35 | INFO     | airflow.models.taskinstance | Marking task as SUCCESS. dag_id=real_estate_etl_taskflow, task_id=extract_zillow, run_id=manual__2026-01-25T07:07:24.739969+00:00, execution_date=20260125T070724, start_date=20260125T070730, end_date=20260125T070735
2026-01-25 07:07:37 | INFO     | etl.transform | STARTING DATA TRANSFORMATION
2026-01-25 07:07:37 | INFO     | etl.transform | Reading input file: /opt/airflow/data/raw/raw_latest.csv
2026-01-25 07:07:37 | INFO     | etl.transform | Loaded 82 raw records
2026-01-25 07:07:37 | INFO     | etl.transform | Columns found: 33
2026-01-25 07:07:37 | INFO     | etl.transform | Step 1: Extracting address components...
2026-01-25 07:07:37 | INFO     | etl.transform | Address components extracted successfully
2026-01-25 07:07:37 | INFO     | etl.transform | Step 2: Extracting listing subtype information...
2026-01-25 07:07:37 | INFO     | etl.transform | Listing subtype flags extracted
2026-01-25 07:07:37 | INFO     | etl.transform | Step 3: Converting timestamp fields...
2026-01-25 07:07:37 | INFO     | etl.transform | Converted datePriceChanged to datetime
2026-01-25 07:07:37 | INFO     | etl.transform | Step 4: Add snapshot dates...
2026-01-25 07:07:37 | INFO     | etl.transform | Snapshot dates added
2026-01-25 07:07:37 | INFO     | etl.transform | Step 5: Normalizing lot area to square feet...
2026-01-25 07:07:37 | INFO     | etl.transform | Lot areas normalized to sqft
2026-01-25 07:07:37 | INFO     | etl.transform | Step 6: Extracting Vegas districts...
2026-01-25 07:07:37 | INFO     | etl.transform | Identified 6 unique districts
2026-01-25 07:07:37 | INFO     | etl.transform | Step 7: Removing unnecessary columns...
2026-01-25 07:07:37 | INFO     | etl.transform | Removed 7 unnecessary columns
2026-01-25 07:07:37 | INFO     | etl.transform | Processed at: 2026-01-25 07:07:37
2026-01-25 07:07:37 | INFO     | etl.transform | All records passed essential field validation
2026-01-25 07:07:37 | INFO     | etl.transform | Final record count: 82
2026-01-25 07:07:37 | INFO     | etl.transform | Saved timestamped file: /opt/airflow/data/transformed/transformed_20260125.csv
2026-01-25 07:07:37 | INFO     | etl.transform | Saved latest file: /opt/airflow/data/transformed/transformed_latest.csv
2026-01-25 07:07:37 | INFO     | etl.transform | TRANSFORMATION SUMMARY
2026-01-25 07:07:37 | INFO     | etl.transform | Input file: raw_latest.csv
2026-01-25 07:07:37 | INFO     | etl.transform | Initial records: 82
2026-01-25 07:07:37 | INFO     | etl.transform | Final records: 82
2026-01-25 07:07:37 | INFO     | etl.transform | Records filtered: 0 (0.0%)
2026-01-25 07:07:37 | INFO     | etl.transform | Output directory: /opt/airflow/data/transformed
2026-01-25 07:07:37 | INFO     | airflow.task.operators.airflow.decorators.python._PythonDecoratedOperator | Done. Returned value was: {'records_transformed': 82, 'file_path': '/opt/airflow/data/transformed/transformed_latest.csv', 'transformation_efficiency': 100.0, 'records_filtered': 0}
2026-01-25 07:07:37 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 07:07:37 | INFO     | airflow.models.taskinstance | Marking task as SUCCESS. dag_id=real_estate_etl_taskflow, task_id=transform_data, run_id=manual__2026-01-25T07:07:24.739969+00:00, execution_date=20260125T070724, start_date=20260125T070737, end_date=20260125T070737
2026-01-25 07:07:40 | INFO     | etl.load | STARTING DATA LOAD TO POSTGRESQL
2026-01-25 07:07:40 | INFO     | etl.load | Loading file: /opt/airflow/data/transformed/transformed_latest.csv
2026-01-25 07:07:40 | INFO     | etl.load | Connecting to PostgreSQL (docker): postgres:5432/docker_real_estate as db_user
2026-01-25 07:07:40 | INFO     | etl.load | Creating schema if not exists: real_estate_data
2026-01-25 07:07:40 | INFO     | etl.load | Creating table if not exists: real_estate_data.properties_data_history
2026-01-25 07:07:40 | INFO     | etl.load | Schema and objects verified/created
2026-01-25 07:07:40 | INFO     | etl.load | Loaded 82 records from CSV
2026-01-25 07:07:40 | INFO     | etl.load | Columns: 27
2026-01-25 07:07:40 | INFO     | etl.load | Created temporary file: /tmp/property_history_load.csv
2026-01-25 07:07:40 | INFO     | etl.load | COPY completed successfully
2026-01-25 07:07:40 | INFO     | etl.load | Total rows in history table: 736
2026-01-25 07:07:40 | INFO     | etl.load | Database connection closed
2026-01-25 07:07:40 | INFO     | airflow.task.operators.airflow.decorators.python._PythonDecoratedOperator | Done. Returned value was: {'postgres_rows': 736, 'records_loaded': 82}
2026-01-25 07:07:40 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 07:07:40 | INFO     | airflow.models.taskinstance | Marking task as SUCCESS. dag_id=real_estate_etl_taskflow, task_id=load_postgres, run_id=manual__2026-01-25T07:07:24.739969+00:00, execution_date=20260125T070724, start_date=20260125T070740, end_date=20260125T070740
2026-01-25 07:07:42 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 07:07:42 | ERROR    | airflow.task | Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/test_dag.py", line 201, in load_s3
    snapshot_date = extraction_metrics["extraction_timestamp"].dt.strftime("%Y%m%d")
AttributeError: 'str' object has no attribute 'dt'
2026-01-25 07:07:42 | INFO     | airflow.models.taskinstance | Marking task as UP_FOR_RETRY. dag_id=real_estate_etl_taskflow, task_id=load_s3, run_id=manual__2026-01-25T07:07:24.739969+00:00, execution_date=20260125T070724, start_date=20260125T070742, end_date=20260125T070742
2026-01-25 07:07:42 | ERROR    | airflow.task.task_runner.standard_task_runner.StandardTaskRunner | Failed to execute job 93 for task load_s3 ('str' object has no attribute 'dt'; 239)
2026-01-25 07:08:03 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:08:03 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:08:34 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:08:34 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:09:05 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:09:05 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:09:36 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:09:36 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:10:07 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:10:07 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:10:32 | INFO     | botocore.credentials | Found credentials in environment variables.
2026-01-25 07:10:33 | INFO     | etl.load_to_s3 | File /opt/airflow/data/raw/raw_latest.csv uploaded to s3://real-estate-scraped-data/raw/raw_20260125_20260125_0710.csv
2026-01-25 07:10:34 | INFO     | etl.load_to_s3 | File /opt/airflow/data/transformed/transformed_latest.csv uploaded to s3://real-estate-scraped-data/transformed/transformed_20260125_20260125_0710.csv
2026-01-25 07:10:34 | INFO     | airflow.task.operators.airflow.decorators.python._PythonDecoratedOperator | Done. Returned value was: {'s3_success': True, 'bucket': 'real-estate-scraped-data'}
2026-01-25 07:10:34 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 07:10:34 | INFO     | airflow.models.taskinstance | Marking task as SUCCESS. dag_id=real_estate_etl_taskflow, task_id=load_s3, run_id=manual__2026-01-25T07:07:24.739969+00:00, execution_date=20260125T070724, start_date=20260125T071030, end_date=20260125T071034
2026-01-25 07:10:36 | INFO     | etl.email_notifier | Email notifier initialized: havando1802@gmail.com -> havando1802@gmail.com
2026-01-25 07:10:36 | INFO     | etl.email_notifier | Preparing success email notification...
2026-01-25 07:10:36 | INFO     | etl.email_notifier | Connecting to SMTP server: smtp.gmail.com:587
2026-01-25 07:10:38 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:10:38 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-01-25 07:10:38 | INFO     | etl.email_notifier | Email notification sent successfully to havando1802@gmail.com
2026-01-25 07:10:38 | INFO     | airflow.task.operators.airflow.decorators.python._PythonDecoratedOperator | Done. Returned value was: None
2026-01-25 07:10:38 | INFO     | airflow.models.taskinstance | ::group::Post task execution logs
2026-01-25 07:10:38 | INFO     | airflow.models.taskinstance | Marking task as SUCCESS. dag_id=real_estate_etl_taskflow, task_id=send_notification, run_id=manual__2026-01-25T07:07:24.739969+00:00, execution_date=20260125T070724, start_date=20260125T071036, end_date=20260125T071038
2026-01-25 07:11:08 | INFO     | airflow.models.dag | Sync 1 DAGs
2026-01-25 07:11:08 | INFO     | airflow.models.dag | Setting next_dagrun for real_estate_etl_pipeline to 2026-01-24 06:00:00+00:00, run_after=2026-01-25 06:00:00+00:00
2026-02-04 21:48:11 | INFO     | __main__ | Starting Zillow data extraction script:
2026-02-04 21:48:11 | INFO     | __main__ | STARTING DATA EXTRACTION FROM ALL LISTED LOCATIONS
2026-02-04 21:48:11 | INFO     | __main__ | Locations configured: 1
2026-02-04 21:48:11 | INFO     | __main__ | Target locations: Las Vegas, NV
2026-02-04 21:48:11 | INFO     | __main__ | Processing location: Las Vegas, NV
2026-02-04 21:48:11 | INFO     | __main__ | Starting extraction for location: Las Vegas, NV (max_pages: 2)
2026-02-04 21:48:11 | INFO     | __main__ | Fetching page 1 for Las Vegas, NV
2026-02-04 21:48:13 | INFO     | __main__ | Page 1 fetched successfully - Properties: 41, Duration: 1.81s
2026-02-04 21:48:13 | INFO     | __main__ | Fetching page 2 for Las Vegas, NV
2026-02-04 21:48:14 | INFO     | __main__ | Page 2 fetched successfully - Properties: 41, Duration: 0.93s
2026-02-04 21:48:14 | INFO     | __main__ | Extraction complete for Las Vegas, NV - Total properties: 82, Pages processed: 2
2026-02-04 21:48:14 | INFO     | __main__ | SUCCESS - Fetched 82 properties from Las Vegas, NV
2026-02-04 21:48:16 | INFO     | __main__ | EXTRACTION SUMMARY
2026-02-04 21:48:16 | INFO     | __main__ | Locations processed: 1
2026-02-04 21:48:16 | INFO     | __main__ | Successful: 1
2026-02-04 21:48:16 | INFO     | __main__ | Failed: 0
2026-02-04 21:48:16 | INFO     | __main__ | Total properties fetched: 82
2026-02-04 21:48:16 | INFO     | __main__ | Unique properties: 82
2026-02-04 21:48:16 | INFO     | __main__ | Duplicates removed: 0
2026-02-04 21:48:16 | INFO     | __main__ | Saved timestamped file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/raw/raw_20260204.csv
2026-02-04 21:48:16 | INFO     | __main__ | Saved latest file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/raw/raw_latest.csv
2026-02-04 21:48:16 | INFO     | __main__ | 
======================================================================
2026-02-04 21:48:16 | INFO     | __main__ | EXTRACTION COMPLETED SUCCESSFULLY
2026-02-04 21:48:16 | INFO     | __main__ | ======================================================================
2026-02-04 21:48:16 | INFO     | __main__ | Total unique properties: 82
2026-02-04 21:48:16 | INFO     | __main__ | Total duration: 0:00:05.196340
2026-02-04 21:48:16 | INFO     | __main__ | ======================================================================
2026-02-04 22:01:02 | INFO     | __main__ | Real Estate ETL Pipeline - Main Entry Point

2026-02-04 22:01:02 | INFO     | email_notifier | Email notifier initialized: havando1802@gmail.com -> havando1802@gmail.com
2026-02-04 22:01:02 | INFO     | __main__ | STARTING REAL ESTATE ETL PIPELINE
2026-02-04 22:01:02 | INFO     | __main__ | Environment: Local | ETL Run ID: 20260204_2201
2026-02-04 22:01:02 | INFO     | __main__ | STAGE 1: EXTRACT
2026-02-04 22:01:02 | INFO     | extract | STARTING DATA EXTRACTION FROM ALL LISTED LOCATIONS
2026-02-04 22:01:02 | INFO     | extract | Locations configured: 1
2026-02-04 22:01:02 | INFO     | extract | Target locations: Las Vegas, NV
2026-02-04 22:01:02 | INFO     | extract | Processing location: Las Vegas, NV
2026-02-04 22:01:02 | INFO     | extract | Starting extraction for location: Las Vegas, NV (max_pages: 2)
2026-02-04 22:01:02 | INFO     | extract | Fetching page 1 for Las Vegas, NV
2026-02-04 22:01:03 | INFO     | extract | Page 1 fetched successfully - Properties: 41, Duration: 1.34s
2026-02-04 22:01:03 | INFO     | extract | Fetching page 2 for Las Vegas, NV
2026-02-04 22:01:04 | INFO     | extract | Page 2 fetched successfully - Properties: 41, Duration: 1.03s
2026-02-04 22:01:04 | INFO     | extract | Extraction complete for Las Vegas, NV - Total properties: 82, Pages processed: 2
2026-02-04 22:01:04 | INFO     | extract | SUCCESS - Fetched 82 properties from Las Vegas, NV
2026-02-04 22:01:06 | INFO     | extract | EXTRACTION SUMMARY
2026-02-04 22:01:06 | INFO     | extract | Locations processed: 1
2026-02-04 22:01:06 | INFO     | extract | Successful: 1
2026-02-04 22:01:06 | INFO     | extract | Failed: 0
2026-02-04 22:01:06 | INFO     | extract | Total properties fetched: 82
2026-02-04 22:01:06 | INFO     | extract | Unique properties: 82
2026-02-04 22:01:06 | INFO     | extract | Duplicates removed: 0
2026-02-04 22:01:06 | INFO     | extract | Saved timestamped file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/raw/raw_20260204.csv
2026-02-04 22:01:06 | INFO     | extract | Saved latest file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/raw/raw_latest.csv
2026-02-04 22:01:06 | INFO     | __main__ | EXTRACT COMPLETED: 82 properties
2026-02-04 22:01:06 | INFO     | __main__ | STAGE 2: TRANSFORM
2026-02-04 22:01:06 | INFO     | transform | STARTING DATA TRANSFORMATION
2026-02-04 22:01:06 | INFO     | transform | Reading input file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/raw/raw_latest.csv
2026-02-04 22:01:07 | INFO     | transform | Loaded 82 raw records
2026-02-04 22:01:07 | INFO     | transform | Columns found: 33
2026-02-04 22:01:07 | INFO     | transform | Step 1: Extracting address components...
2026-02-04 22:01:07 | INFO     | transform | Address components extracted successfully
2026-02-04 22:01:07 | INFO     | transform | Step 2: Extracting listing subtype information...
2026-02-04 22:01:07 | INFO     | transform | Listing subtype flags extracted
2026-02-04 22:01:07 | INFO     | transform | Step 3: Converting timestamp fields...
2026-02-04 22:01:07 | INFO     | transform | Converted datePriceChanged to datetime
2026-02-04 22:01:07 | INFO     | transform | Step 4: Add snapshot dates...
2026-02-04 22:01:07 | INFO     | transform | Snapshot dates added
2026-02-04 22:01:07 | INFO     | transform | Step 5: Normalizing lot area to square feet...
2026-02-04 22:01:07 | INFO     | transform | Lot areas normalized to sqft
2026-02-04 22:01:07 | INFO     | transform | Step 6: Extracting Vegas districts...
2026-02-04 22:01:07 | INFO     | transform | Identified 5 unique districts
2026-02-04 22:01:07 | INFO     | transform | Step 7: Removing unnecessary columns...
2026-02-04 22:01:07 | INFO     | transform | Removed 7 unnecessary columns
2026-02-04 22:01:07 | INFO     | transform | Processed at: 2026-02-04 22:01:07
2026-02-04 22:01:07 | INFO     | transform | All records passed essential field validation
2026-02-04 22:01:07 | INFO     | transform | Final record count: 82
2026-02-04 22:01:07 | INFO     | transform | Saved timestamped file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/transformed/transformed_20260204.csv
2026-02-04 22:01:07 | INFO     | transform | Saved latest file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/transformed/transformed_latest.csv
2026-02-04 22:01:07 | INFO     | transform | TRANSFORMATION SUMMARY
2026-02-04 22:01:07 | INFO     | transform | Input file: raw_latest.csv
2026-02-04 22:01:07 | INFO     | transform | Initial records: 82
2026-02-04 22:01:07 | INFO     | transform | Final records: 82
2026-02-04 22:01:07 | INFO     | transform | Records filtered: 0 (0.0%)
2026-02-04 22:01:07 | INFO     | transform | Output directory: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/transformed
2026-02-04 22:01:07 | INFO     | __main__ | TRANSFORM COMPLETED
2026-02-04 22:01:07 | INFO     | __main__ | STAGE 3: LOAD
2026-02-04 22:01:07 | INFO     | load | STARTING DATA LOAD TO POSTGRESQL
2026-02-04 22:01:07 | INFO     | load | Loading file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/transformed/transformed_latest.csv
2026-02-04 22:01:07 | INFO     | load | Connecting to PostgreSQL (local): localhost:5432/zillow_api as postgres
2026-02-04 22:01:07 | INFO     | load | Creating schema if not exists: real_estate_data
2026-02-04 22:01:07 | INFO     | load | Creating table if not exists: real_estate_data.properties_data_history
2026-02-04 22:01:07 | INFO     | load | Schema and objects verified/created
2026-02-04 22:01:07 | INFO     | load | Loaded 82 records from CSV
2026-02-04 22:01:07 | INFO     | load | Columns: 27
2026-02-04 22:01:07 | INFO     | load | Created temporary file: /tmp/property_history_load.csv
2026-02-04 22:01:07 | INFO     | load | COPY completed successfully
2026-02-04 22:01:07 | INFO     | load | Total rows in history table: 410
2026-02-04 22:01:07 | INFO     | load | Database connection closed
2026-02-04 22:01:07 | INFO     | __main__ | LOAD COMPLETED

2026-02-04 22:01:07 | INFO     | __main__ | Load to S3
2026-02-04 22:01:08 | INFO     | load_to_s3 | File /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/raw/raw_latest.csv uploaded to s3://real-estate-scraped-data/raw/raw_20260204_20260204_2201.csv
2026-02-04 22:01:08 | INFO     | load_to_s3 | File /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/transformed/transformed_latest.csv uploaded to s3://real-estate-scraped-data/transformed/transformed_20260204_20260204_2201.csv
2026-02-04 22:01:08 | INFO     | __main__ | LOAD TO S3 COMPLETED

2026-02-04 22:01:08 | INFO     | __main__ | ETL PIPELINE COMPLETED SUCCESSFULLY
2026-02-04 22:01:08 | INFO     | __main__ | Duration: 0:00:06 | Quality: 100.0%
2026-02-04 22:01:08 | INFO     | __main__ | Sending success email...
2026-02-04 22:01:08 | INFO     | email_notifier | Preparing success email notification...
2026-02-04 22:01:08 | INFO     | email_notifier | Connecting to SMTP server: smtp.gmail.com:587
2026-02-04 22:01:11 | INFO     | email_notifier | Email notification sent successfully to havando1802@gmail.com
2026-02-07 11:26:16 | INFO     | __main__ | Real Estate ETL Pipeline - Main Entry Point

2026-02-07 11:26:16 | INFO     | email_notifier | Email notifier initialized: havando1802@gmail.com -> havando1802@gmail.com
2026-02-07 11:26:16 | INFO     | __main__ | STARTING REAL ESTATE ETL PIPELINE
2026-02-07 11:26:16 | INFO     | __main__ | Environment: Local | ETL Run ID: 20260207_1126
2026-02-07 11:26:16 | INFO     | __main__ | STAGE 1: EXTRACT
2026-02-07 11:26:16 | INFO     | extract | STARTING DATA EXTRACTION FROM ALL LISTED LOCATIONS
2026-02-07 11:26:16 | INFO     | extract | Locations configured: 1
2026-02-07 11:26:16 | INFO     | extract | Target locations: Las Vegas, NV
2026-02-07 11:26:16 | INFO     | extract | Processing location: Las Vegas, NV
2026-02-07 11:26:16 | INFO     | extract | Starting extraction for location: Las Vegas, NV (max_pages: 5)
2026-02-07 11:26:16 | INFO     | extract | Fetching page 1 for Las Vegas, NV
2026-02-07 11:26:19 | INFO     | extract | Page 1 fetched successfully - Properties: 41, Duration: 2.85s
2026-02-07 11:26:19 | INFO     | extract | Fetching page 2 for Las Vegas, NV
2026-02-07 11:26:20 | INFO     | extract | Page 2 fetched successfully - Properties: 41, Duration: 1.58s
2026-02-07 11:26:21 | INFO     | extract | Fetching page 3 for Las Vegas, NV
2026-02-07 11:26:22 | INFO     | extract | Page 3 fetched successfully - Properties: 41, Duration: 1.38s
2026-02-07 11:26:22 | INFO     | extract | Fetching page 4 for Las Vegas, NV
2026-02-07 11:26:23 | INFO     | extract | Page 4 fetched successfully - Properties: 41, Duration: 1.13s
2026-02-07 11:26:24 | INFO     | extract | Fetching page 5 for Las Vegas, NV
2026-02-07 11:26:25 | INFO     | extract | Page 5 fetched successfully - Properties: 41, Duration: 1.87s
2026-02-07 11:26:26 | INFO     | extract | Extraction complete for Las Vegas, NV - Total properties: 205, Pages processed: 5
2026-02-07 11:26:26 | INFO     | extract | SUCCESS - Fetched 205 properties from Las Vegas, NV
2026-02-07 11:26:28 | INFO     | extract | EXTRACTION SUMMARY
2026-02-07 11:26:28 | INFO     | extract | Locations processed: 1
2026-02-07 11:26:28 | INFO     | extract | Successful: 1
2026-02-07 11:26:28 | INFO     | extract | Failed: 0
2026-02-07 11:26:28 | INFO     | extract | Total properties fetched: 205
2026-02-07 11:26:28 | INFO     | extract | Unique properties: 205
2026-02-07 11:26:28 | INFO     | extract | Duplicates removed: 0
2026-02-07 11:26:28 | INFO     | extract | Saved timestamped file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/raw/raw_20260207.csv
2026-02-07 11:26:28 | INFO     | extract | Saved latest file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/raw/raw_latest.csv
2026-02-07 11:26:28 | INFO     | __main__ | EXTRACT COMPLETED: 205 properties
2026-02-07 11:26:28 | INFO     | __main__ | STAGE 2: TRANSFORM
2026-02-07 11:26:28 | INFO     | transform | STARTING DATA TRANSFORMATION
2026-02-07 11:26:28 | INFO     | transform | Reading input file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/raw/raw_latest.csv
2026-02-07 11:26:28 | INFO     | transform | Loaded 205 raw records
2026-02-07 11:26:28 | INFO     | transform | Columns found: 33
2026-02-07 11:26:28 | INFO     | transform | Step 1: Extracting address components...
2026-02-07 11:26:28 | INFO     | transform | Address components extracted successfully
2026-02-07 11:26:28 | INFO     | transform | Step 2: Extracting listing subtype information...
2026-02-07 11:26:28 | INFO     | transform | Listing subtype flags extracted
2026-02-07 11:26:28 | INFO     | transform | Step 3: Converting timestamp fields...
2026-02-07 11:26:28 | INFO     | transform | Converted datePriceChanged to datetime
2026-02-07 11:26:28 | INFO     | transform | Step 4: Add snapshot dates...
2026-02-07 11:26:28 | INFO     | transform | Snapshot dates added
2026-02-07 11:26:28 | INFO     | transform | Step 5: Normalizing lot area to square feet...
2026-02-07 11:26:28 | INFO     | transform | Lot areas normalized to sqft
2026-02-07 11:26:28 | INFO     | transform | Step 6: Extracting Vegas districts...
2026-02-07 11:26:28 | INFO     | transform | Identified 9 unique districts
2026-02-07 11:26:28 | INFO     | transform | Step 7: Removing unnecessary columns...
2026-02-07 11:26:28 | INFO     | transform | Removed 7 unnecessary columns
2026-02-07 11:26:28 | INFO     | transform | Processed at: 2026-02-07 11:26:28
2026-02-07 11:26:28 | INFO     | transform | All records passed essential field validation
2026-02-07 11:26:28 | INFO     | transform | Final record count: 205
2026-02-07 11:26:28 | INFO     | transform | Saved timestamped file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/transformed/transformed_20260207.csv
2026-02-07 11:26:28 | INFO     | transform | Saved latest file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/transformed/transformed_latest.csv
2026-02-07 11:26:28 | INFO     | transform | TRANSFORMATION SUMMARY
2026-02-07 11:26:28 | INFO     | transform | Input file: raw_latest.csv
2026-02-07 11:26:28 | INFO     | transform | Initial records: 205
2026-02-07 11:26:28 | INFO     | transform | Final records: 205
2026-02-07 11:26:28 | INFO     | transform | Records filtered: 0 (0.0%)
2026-02-07 11:26:28 | INFO     | transform | Output directory: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/transformed
2026-02-07 11:26:28 | INFO     | __main__ | TRANSFORM COMPLETED
2026-02-07 11:26:28 | INFO     | __main__ | STAGE 3: LOAD
2026-02-07 11:26:28 | INFO     | load | STARTING DATA LOAD TO POSTGRESQL
2026-02-07 11:26:28 | INFO     | load | Loading file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/transformed/transformed_latest.csv
2026-02-07 11:26:28 | INFO     | load | Connecting to PostgreSQL (local): localhost:5432/zillow_api as postgres
2026-02-07 11:26:28 | INFO     | load | Creating schema if not exists: real_estate_data
2026-02-07 11:26:28 | INFO     | load | Creating table if not exists: real_estate_data.properties_data_history
2026-02-07 11:26:28 | INFO     | load | Schema and objects verified/created
2026-02-07 11:26:28 | INFO     | load | Loaded 205 records from CSV
2026-02-07 11:26:28 | INFO     | load | Columns: 27
2026-02-07 11:26:28 | INFO     | load | Created temporary file: /tmp/property_history_load.csv
2026-02-07 11:26:28 | INFO     | load | COPY completed successfully
2026-02-07 11:26:28 | INFO     | load | Total rows in history table: 615
2026-02-07 11:26:28 | INFO     | load | Database connection closed
2026-02-07 11:26:28 | INFO     | __main__ | LOAD COMPLETED

2026-02-07 11:26:28 | INFO     | __main__ | Load to S3
2026-02-07 11:26:29 | INFO     | load_to_s3 | File /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/raw/raw_latest.csv uploaded to s3://real-estate-scraped-data/raw/raw_20260207_20260207_1126.csv
2026-02-07 11:26:29 | INFO     | load_to_s3 | File /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/transformed/transformed_latest.csv uploaded to s3://real-estate-scraped-data/transformed/transformed_20260207_20260207_1126.csv
2026-02-07 11:26:29 | INFO     | __main__ | LOAD TO S3 COMPLETED

2026-02-07 11:26:29 | INFO     | __main__ | ETL PIPELINE COMPLETED SUCCESSFULLY
2026-02-07 11:26:29 | INFO     | __main__ | Duration: 0:00:13 | Quality: 100.0%
2026-02-07 11:26:29 | INFO     | __main__ | Sending success email...
2026-02-07 11:26:29 | INFO     | email_notifier | Preparing success email notification...
2026-02-07 11:26:29 | INFO     | email_notifier | Connecting to SMTP server: smtp.gmail.com:587
2026-02-07 11:26:31 | INFO     | email_notifier | Email notification sent successfully to havando1802@gmail.com
2026-02-07 15:05:47 | INFO     | __main__ | Running in Local environment

2026-02-07 15:05:47 | INFO     | __main__ | STARTING DATA TRANSFORMATION
2026-02-07 15:05:47 | INFO     | __main__ | Reading input file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/raw/raw_latest.csv
2026-02-07 15:05:47 | INFO     | __main__ | Loaded 205 raw records
2026-02-07 15:05:47 | INFO     | __main__ | Columns found: 33
2026-02-07 15:05:47 | INFO     | __main__ | Step 1: Extracting address components...
2026-02-07 15:05:47 | INFO     | __main__ | Address components extracted successfully
2026-02-07 15:05:47 | INFO     | __main__ | Step 2: Extracting listing subtype information...
2026-02-07 15:05:47 | INFO     | __main__ | Listing subtype flags extracted
2026-02-07 15:05:47 | INFO     | __main__ | Step 3: Converting timestamp fields...
2026-02-07 15:05:48 | INFO     | __main__ | Converted datePriceChanged to datetime
2026-02-07 15:05:48 | INFO     | __main__ | Step 4: Add snapshot dates...
2026-02-07 15:05:48 | INFO     | __main__ | Snapshot dates added
2026-02-07 15:05:48 | INFO     | __main__ | Step 5: Normalizing lot area to square feet...
2026-02-07 15:05:48 | INFO     | __main__ | Lot areas normalized to sqft
2026-02-07 15:05:48 | INFO     | __main__ | Step 6: Extracting Vegas districts...
2026-02-07 15:05:48 | INFO     | __main__ | Identified 9 unique districts
2026-02-07 15:05:48 | INFO     | __main__ | Step 7: Removing unnecessary columns...
2026-02-07 15:05:48 | INFO     | __main__ | Removed 7 unnecessary columns
2026-02-07 15:05:48 | INFO     | __main__ | Processed at: 2026-02-07 23:05:48
2026-02-07 15:05:48 | INFO     | __main__ | All records passed essential field validation
2026-02-07 15:05:48 | INFO     | __main__ | Final record count: 205
2026-02-07 15:05:48 | INFO     | __main__ | Saved timestamped file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/transformed/transformed_20260207.csv
2026-02-07 15:05:48 | INFO     | __main__ | Saved latest file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/transformed/transformed_latest.csv
2026-02-07 15:05:48 | INFO     | __main__ | TRANSFORMATION SUMMARY
2026-02-07 15:05:48 | INFO     | __main__ | Input file: raw_latest.csv
2026-02-07 15:05:48 | INFO     | __main__ | Initial records: 205
2026-02-07 15:05:48 | INFO     | __main__ | Final records: 205
2026-02-07 15:05:48 | INFO     | __main__ | Records filtered: 0 (0.0%)
2026-02-07 15:05:48 | INFO     | __main__ | Output directory: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/transformed
2026-02-07 15:05:48 | INFO     | __main__ | TRANSFORMATION COMPLETED SUCCESSFULLY
2026-02-07 15:05:48 | INFO     | __main__ | Total duration: 0:00:00.105843
2026-02-07 15:05:48 | INFO     | __main__ | Records transformed: 205
2026-02-07 15:06:00 | INFO     | __main__ | RUNNING IN LOCAL ENVIRONMENT
2026-02-07 15:06:00 | INFO     | __main__ | 
Configuration:
2026-02-07 15:06:00 | INFO     | __main__ |   Raw file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/raw/raw_latest.csv
2026-02-07 15:06:00 | INFO     | __main__ |   Transformed file: /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/transformed/transformed_latest.csv
2026-02-07 15:06:00 | INFO     | __main__ |   S3 bucket: real-estate-scraped-data
2026-02-07 15:06:00 | INFO     | __main__ |   S3 raw prefix: raw
2026-02-07 15:06:00 | INFO     | __main__ |   S3 transformed prefix: transformed
2026-02-07 15:06:00 | INFO     | __main__ |   Postgres load: disabled (handled downstream)
2026-02-07 15:06:00 | INFO     | __main__ | STARTING DATA LOAD TO S3 (RAW + TRANSFORMED)
2026-02-07 15:06:00 | INFO     | __main__ | File /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/raw/raw_latest.csv uploaded to s3://real-estate-scraped-data/raw/raw_20260207_20260207_2306.csv
2026-02-07 15:06:01 | INFO     | __main__ | File /Users/hado/Desktop/Career/Coding/Data Engineer/Project/real_estate_extract/data/transformed/transformed_latest.csv uploaded to s3://real-estate-scraped-data/transformed/transformed_20260207_20260207_2306.csv
2026-02-07 15:06:01 | INFO     | __main__ | S3 uploads completed successfully
2026-02-07 15:06:01 | INFO     | __main__ | DATA LOAD COMPLETED SUCCESSFULLY
2026-02-07 15:06:01 | INFO     | __main__ | Duration: 0:00:01.008661
